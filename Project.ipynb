{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21602,"status":"ok","timestamp":1718349568754,"user":{"displayName":"Giansimone Coccia","userId":"03098038543387348591"},"user_tz":-120},"id":"SjgTYOSGW6Eg","outputId":"554a4cc1-dba7-4608-8233-6bc460c15923"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":141505,"status":"ok","timestamp":1718349725598,"user":{"displayName":"Giansimone Coccia","userId":"03098038543387348591"},"user_tz":-120},"id":"Ehk39Y2KHsaG","outputId":"941a20e4-6ddf-45c7-84ee-66fbdbf28d00"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ultralytics in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (8.2.16)\n","Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (3.9.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (4.9.0.80)\n","Requirement already satisfied: pillow>=7.1.2 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (10.3.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.13.0)\n","Requirement already satisfied: torch>=1.8.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.3.0)\n","Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.18.0)\n","Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (4.66.4)\n","Requirement already satisfied: psutil in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (5.9.8)\n","Requirement already satisfied: py-cpuinfo in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: thop>=0.1.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n","Requirement already satisfied: pandas>=1.1.4 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.13.2)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: numpy>=1.23 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n","Requirement already satisfied: filelock in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n","Requirement already satisfied: sympy in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.5.0)\n","Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2021.4.0)\n","Requirement already satisfied: colorama in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n","Requirement already satisfied: intel-openmp==2021.* in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.4.0)\n","Requirement already satisfied: tbb==2021.* in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.12.0)\n","Requirement already satisfied: six>=1.5 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: pyfacer in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0.4)\n","Requirement already satisfied: torch>=1.9.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyfacer) (2.3.0)\n","Requirement already satisfied: torchvision in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyfacer) (0.18.0)\n","Requirement already satisfied: pillow in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyfacer) (10.3.0)\n","Requirement already satisfied: numpy in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyfacer) (1.26.4)\n","Requirement already satisfied: ipywidgets in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyfacer) (8.1.2)\n","Requirement already satisfied: scikit-image in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyfacer) (0.23.2)\n","Requirement already satisfied: matplotlib in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyfacer) (3.9.0)\n","Requirement already satisfied: validators in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyfacer) (0.28.1)\n","Requirement already satisfied: requests in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyfacer) (2.31.0)\n","Requirement already satisfied: opencv-python in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyfacer) (4.9.0.80)\n","Requirement already satisfied: filelock in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.9.1->pyfacer) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.9.1->pyfacer) (4.11.0)\n","Requirement already satisfied: sympy in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.9.1->pyfacer) (1.12)\n","Requirement already satisfied: networkx in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.9.1->pyfacer) (3.3)\n","Requirement already satisfied: jinja2 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.9.1->pyfacer) (3.1.4)\n","Requirement already satisfied: fsspec in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.9.1->pyfacer) (2024.5.0)\n","Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.9.1->pyfacer) (2021.4.0)\n","Requirement already satisfied: comm>=0.1.3 in c:\\users\\dswal\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets->pyfacer) (0.2.2)\n","Requirement already satisfied: ipython>=6.1.0 in c:\\users\\dswal\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets->pyfacer) (8.24.0)\n","Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\dswal\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets->pyfacer) (5.14.3)\n","Requirement already satisfied: widgetsnbextension~=4.0.10 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipywidgets->pyfacer) (4.0.10)\n","Requirement already satisfied: jupyterlab-widgets~=3.0.10 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipywidgets->pyfacer) (3.0.10)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->pyfacer) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->pyfacer) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->pyfacer) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->pyfacer) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->pyfacer) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->pyfacer) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->pyfacer) (2.9.0.post0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pyfacer) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pyfacer) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pyfacer) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pyfacer) (2024.2.2)\n","Requirement already satisfied: scipy>=1.9 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image->pyfacer) (1.13.0)\n","Requirement already satisfied: imageio>=2.33 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image->pyfacer) (2.34.1)\n","Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image->pyfacer) (2024.5.10)\n","Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image->pyfacer) (0.4)\n","Requirement already satisfied: decorator in c:\\users\\dswal\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets->pyfacer) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in c:\\users\\dswal\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets->pyfacer) (0.19.1)\n","Requirement already satisfied: matplotlib-inline in c:\\users\\dswal\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets->pyfacer) (0.1.7)\n","Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\dswal\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets->pyfacer) (3.0.43)\n","Requirement already satisfied: pygments>=2.4.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->pyfacer) (2.18.0)\n","Requirement already satisfied: stack-data in c:\\users\\dswal\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets->pyfacer) (0.6.3)\n","Requirement already satisfied: colorama in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->pyfacer) (0.4.6)\n","Requirement already satisfied: intel-openmp==2021.* in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.9.1->pyfacer) (2021.4.0)\n","Requirement already satisfied: tbb==2021.* in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.9.1->pyfacer) (2021.12.0)\n","Requirement already satisfied: six>=1.5 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->pyfacer) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.9.1->pyfacer) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.9.1->pyfacer) (1.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\dswal\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->pyfacer) (0.8.4)\n","Requirement already satisfied: wcwidth in c:\\users\\dswal\\appdata\\roaming\\python\\python312\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->pyfacer) (0.2.13)\n","Requirement already satisfied: executing>=1.2.0 in c:\\users\\dswal\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->pyfacer) (2.0.1)\n","Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\dswal\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->pyfacer) (2.4.1)\n","Requirement already satisfied: pure-eval in c:\\users\\dswal\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->pyfacer) (0.2.2)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: timm in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.3)\n","Requirement already satisfied: torch in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (2.3.0)\n","Requirement already satisfied: torchvision in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (0.18.0)\n","Requirement already satisfied: pyyaml in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface_hub in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (0.23.0)\n","Requirement already satisfied: safetensors in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (0.4.3)\n","Requirement already satisfied: filelock in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (2024.5.0)\n","Requirement already satisfied: packaging>=20.9 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (23.2)\n","Requirement already satisfied: requests in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (4.11.0)\n","Requirement already satisfied: sympy in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (1.12)\n","Requirement already satisfied: networkx in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (3.3)\n","Requirement already satisfied: jinja2 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (3.1.4)\n","Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (2021.4.0)\n","Requirement already satisfied: numpy in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision->timm) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision->timm) (10.3.0)\n","Requirement already satisfied: intel-openmp==2021.* in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->timm) (2021.4.0)\n","Requirement already satisfied: tbb==2021.* in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->timm) (2021.12.0)\n","Requirement already satisfied: colorama in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->timm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch->timm) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: scikit-learn in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.2)\n","Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.13.0)\n","Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: Pillow in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (10.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting plotly\n","  Downloading plotly-5.22.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting tenacity>=6.2.0 (from plotly)\n","  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: packaging in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from plotly) (23.2)\n","Downloading plotly-5.22.0-py3-none-any.whl (16.4 MB)\n","   ---------------------------------------- 0.0/16.4 MB ? eta -:--:--\n","   ---------------------------------------- 0.1/16.4 MB 3.5 MB/s eta 0:00:05\n","   -- ------------------------------------- 0.8/16.4 MB 10.4 MB/s eta 0:00:02\n","   ------ --------------------------------- 2.8/16.4 MB 22.5 MB/s eta 0:00:01\n","   ------------- -------------------------- 5.5/16.4 MB 32.0 MB/s eta 0:00:01\n","   ---------------- ----------------------- 6.6/16.4 MB 35.2 MB/s eta 0:00:01\n","   ---------------- ----------------------- 6.6/16.4 MB 35.2 MB/s eta 0:00:01\n","   ---------------- ----------------------- 6.6/16.4 MB 35.2 MB/s eta 0:00:01\n","   ---------------- ----------------------- 6.6/16.4 MB 35.2 MB/s eta 0:00:01\n","   ---------------- ----------------------- 6.6/16.4 MB 35.2 MB/s eta 0:00:01\n","   ---------------- ----------------------- 6.6/16.4 MB 35.2 MB/s eta 0:00:01\n","   ---------------- ----------------------- 6.7/16.4 MB 14.2 MB/s eta 0:00:01\n","   ---------------- ----------------------- 6.8/16.4 MB 12.8 MB/s eta 0:00:01\n","   ----------------- ---------------------- 7.4/16.4 MB 12.7 MB/s eta 0:00:01\n","   ---------------------- ----------------- 9.0/16.4 MB 14.1 MB/s eta 0:00:01\n","   ------------------------ --------------- 10.2/16.4 MB 15.1 MB/s eta 0:00:01\n","   ---------------------------- ----------- 11.6/16.4 MB 16.0 MB/s eta 0:00:01\n","   ------------------------------- -------- 13.1/16.4 MB 16.0 MB/s eta 0:00:01\n","   ------------------------------------ --- 15.0/16.4 MB 15.6 MB/s eta 0:00:01\n","   ---------------------------------------  16.4/16.4 MB 15.6 MB/s eta 0:00:01\n","   ---------------------------------------- 16.4/16.4 MB 14.2 MB/s eta 0:00:00\n","Downloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n","Installing collected packages: tenacity, plotly\n","Successfully installed plotly-5.22.0 tenacity-8.3.0\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: torchvision in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.18.0)\n","Requirement already satisfied: numpy in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: torch==2.3.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (2.3.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.3.0)\n","Requirement already satisfied: filelock in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (4.11.0)\n","Requirement already satisfied: sympy in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (1.12)\n","Requirement already satisfied: networkx in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (3.3)\n","Requirement already satisfied: jinja2 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (3.1.4)\n","Requirement already satisfied: fsspec in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (2024.5.0)\n","Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.3.0->torchvision) (2021.4.0)\n","Requirement already satisfied: intel-openmp==2021.* in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.4.0)\n","Requirement already satisfied: tbb==2021.* in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.12.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\dswal\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install ultralytics\n","#%pip install glasses-detector\n","%pip install pyfacer\n","%pip install timm\n","%pip install scikit-learn\n","%pip install Pillow\n","%pip install plotly\n","%pip install torchvision\n","\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","#import glasses_detector\n","import concurrent.futures\n","import os\n","import time\n","from PIL import Image\n","import matplotlib.image as mpimg\n","from sklearn.cluster import MiniBatchKMeans\n","from ultralytics import YOLO\n","import numpy as np\n","from sklearn.cluster import KMeans\n","from sklearn.semi_supervised import SelfTrainingClassifier\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics.pairwise import pairwise_distances_argmin_min\n","from sklearn.model_selection import train_test_split\n","from sklearn.semi_supervised import LabelPropagation\n","import torch\n","from torchvision.transforms.functional import to_pil_image\n","import facer\n","import shutil\n","import csv\n","import copy\n","from sklearn.manifold import TSNE\n","from mpl_toolkits.mplot3d import Axes3D\n","from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n","import plotly.graph_objects as go\n","import plotly.express as px\n","from io import BytesIO\n","import base64\n","import multiprocessing\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FdHDpWOTW_e1"},"outputs":[],"source":["# Directory principale del tuo progetto Waltico\n","project_dir = '/content/gdrive/My Drive/Progetto Computer Vision/'"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Directory locale del tuo progetto Waltico\n","project_dir = '/Users/dswal/Desktop/Progetto Computer Vision/Progetto Computer Vision/'"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":281,"status":"ok","timestamp":1718349730883,"user":{"displayName":"Giansimone Coccia","userId":"03098038543387348591"},"user_tz":-120},"id":"zGi3aVdkZ182"},"outputs":[],"source":["# Directory principale del tuo progetto Giansimone\n","project_dir = '/content/gdrive/MyDrive/Colab Notebooks/Computer Vision e Deep Learning/Progetto Computer Vision'"]},{"cell_type":"markdown","metadata":{"id":"g-17S5ynJuDy"},"source":["### Glasses Segmentation"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"5E8mzQgvDbjy"},"outputs":[],"source":["class GlassesSegmentation:\n","    def __init__(self, project_dir):\n","        # Imposta directory di progetto e dispositivo\n","        self._project_dir = project_dir\n","        self._glasses_detector = glasses_detector.AnyglassesClassifier()\n","\n","    def process_images(self):\n","        all_segments = {}\n","        # Processa ciascuna immagine nella directory dei risultati\n","        for filename in os.listdir(os.path.join(self._project_dir, 'data/images')):\n","            image_path = os.path.join(self._project_dir, 'data/images', filename)\n","            print(filename)\n","            image = self._load_image(image_path)\n","            print(image)\n","\n","    def _load_image(self, image_path, csv_filename = 'glasses_per_image.csv'):\n","       # Verifica se la directory per il CSV esiste, altrimenti creala\n","        csv_dir = os.path.join(self._project_dir, 'results/csv')\n","        if not os.path.exists(csv_dir):\n","            os.makedirs(csv_dir)\n","\n","        csv_path = os.path.join(csv_dir, csv_filename)\n","\n","        sus = self._glasses_detector (image_path)\n","        return sus\n"]},{"cell_type":"markdown","metadata":{"id":"iUoHVL8tJe1X"},"source":["### Detection\n"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1718349732578,"user":{"displayName":"Giansimone Coccia","userId":"03098038543387348591"},"user_tz":-120},"id":"78nJCfPpWSmf"},"outputs":[],"source":["\n","class FaceDetection:\n","    def __init__(self, project_dir):\n","        self._project_dir = project_dir\n","        self._model_path = os.path.join(self._project_dir, 'data/models/yolov8l-face.pt')\n","        assert os.path.exists(self._model_path), \"Il percorso del modello non Ã¨ valido\"\n","        self._device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self._model = YOLO(self._model_path).to(self._device)\n","        print(\"Inizializzazione...\")\n","\n","    def face_detection(self, input_dir='data/images', output_dir='results/faces'):\n","        # Prepara le directory di input e output\n","        input_dir = self._prepare_directory(input_dir)\n","        output_dir = self._prepare_directory(output_dir, create=True)\n","        self._clear_directory(output_dir)\n","\n","        # Processa ciascuna immagine nella directory di input\n","        image_files = os.listdir(input_dir)\n","        for i, image_file in enumerate(image_files):\n","            image_path = os.path.join(input_dir, image_file)\n","            results = self._model(image_path).to(self._device)\n","            self._process_results(results, image_path, output_dir, i, len(image_files))\n","\n","        print(\"Processo concluso con successo\")\n","\n","    def _clear_directory(self, output_dir):\n","        # Verifica se la directory esiste\n","        if os.path.exists(output_dir):\n","            # Itera sui file nella directory e rimuovili\n","            for filename in os.listdir(output_dir):\n","                file_path = os.path.join(output_dir, filename)\n","                try:\n","                    if os.path.isfile(file_path) or os.path.islink(file_path):\n","                        os.unlink(file_path)\n","                    elif os.path.isdir(file_path):\n","                        shutil.rmtree(file_path)\n","                except Exception as e:\n","                    print(f\"Errore durante la rimozione di {file_path}: {e}\")\n","            print(f\"Contenuto di {output_dir} svuotato.\")\n","        else:\n","            print(f\"La directory {output_dir} non esiste.\")\n","\n","    def _prepare_directory(self, dir_path, create=False):\n","        # Costruisce il percorso completo della directory\n","        full_path = os.path.join(self._project_dir, dir_path)\n","        if create and not os.path.exists(full_path):\n","            os.makedirs(full_path)\n","            print(f\"Directory creata: {full_path}\")\n","        return full_path\n","\n","    def _process_results(self, results, image_path, output_dir, image_index, total_images):\n","        # Ritaglia e salva le immagini di ciascuna bounding box rilevata\n","        img = Image.open(image_path).convert(\"RGB\")\n","        for result in results:\n","            boxes = result.boxes.data\n","            for box_index, box in enumerate(boxes):\n","                cropped_img = self._crop_image(img, box)\n","                output_file = self._generate_output_filename(output_dir, image_index, total_images, box_index, len(boxes))\n","                cropped_img.save(output_file)\n","\n","    def _crop_image(self, img, box):\n","        # Ritaglia l'immagine utilizzando le coordinate della bounding box\n","        x_min, y_min, x_max, y_max = box[:4].tolist()\n","        return img.crop((x_min, y_min, x_max, y_max))\n","\n","    def _generate_output_filename(self, output_dir, image_index, total_images, box_index, total_boxes):\n","        # Genera un nome di file per l'immagine ritagliata\n","        image_index_str = str(image_index).zfill(len(str(total_images)))\n","        box_index_str = str(box_index).zfill(len(str(total_boxes)))\n","        return os.path.join(output_dir, f'result_{image_index_str}_{box_index_str}.jpg')\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":826816,"status":"ok","timestamp":1718350571817,"user":{"displayName":"Giansimone Coccia","userId":"03098038543387348591"},"user_tz":-120},"id":"FZWkQwmgJv78","outputId":"91b68233-a7ef-487d-c0b0-f6b2941dbb86"},"outputs":[{"name":"stdout","output_type":"stream","text":["Inizializzazione...\n","Contenuto di /Users/dswal/Desktop/Progetto Computer Vision/Progetto Computer Vision/results/faces svuotato.\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 0.jpg: 960x960 1 face, 5545.0ms\n","Speed: 44.6ms preprocess, 5545.0ms inference, 20.1ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1.jpg: 960x960 1 face, 5690.0ms\n","Speed: 22.8ms preprocess, 5690.0ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 10.jpg: 960x960 2 faces, 5784.5ms\n","Speed: 20.8ms preprocess, 5784.5ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 100.jpg: 960x960 1 face, 6919.4ms\n","Speed: 25.0ms preprocess, 6919.4ms inference, 4.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1000.jpg: 960x960 2 faces, 6197.6ms\n","Speed: 26.5ms preprocess, 6197.6ms inference, 8.7ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1001.jpg: 960x960 1 face, 6390.0ms\n","Speed: 45.4ms preprocess, 6390.0ms inference, 3.4ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1002.jpg: 960x960 1 face, 6949.8ms\n","Speed: 25.2ms preprocess, 6949.8ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1003.jpg: 960x960 1 face, 7608.2ms\n","Speed: 25.4ms preprocess, 7608.2ms inference, 6.9ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1004.jpg: 960x960 1 face, 7330.6ms\n","Speed: 32.0ms preprocess, 7330.6ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1005.jpg: 960x960 1 face, 6146.2ms\n","Speed: 28.0ms preprocess, 6146.2ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1006.jpg: 960x960 1 face, 5307.3ms\n","Speed: 24.5ms preprocess, 5307.3ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1007.jpg: 960x960 1 face, 5396.4ms\n","Speed: 21.7ms preprocess, 5396.4ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1008.jpg: 960x960 1 face, 6108.6ms\n","Speed: 26.4ms preprocess, 6108.6ms inference, 7.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1009.jpg: 960x960 1 face, 5862.9ms\n","Speed: 27.5ms preprocess, 5862.9ms inference, 4.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 101.jpg: 960x960 1 face, 5940.3ms\n","Speed: 27.6ms preprocess, 5940.3ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1010.jpg: 960x960 1 face, 6988.4ms\n","Speed: 24.6ms preprocess, 6988.4ms inference, 4.4ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1011.jpg: 960x960 1 face, 5602.0ms\n","Speed: 30.0ms preprocess, 5602.0ms inference, 3.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1012.jpg: 960x960 1 face, 5718.2ms\n","Speed: 31.9ms preprocess, 5718.2ms inference, 2.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1013.jpg: 960x960 1 face, 5667.8ms\n","Speed: 26.5ms preprocess, 5667.8ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1014.jpg: 960x960 1 face, 5213.4ms\n","Speed: 19.6ms preprocess, 5213.4ms inference, 5.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1015.jpg: 960x960 1 face, 5828.8ms\n","Speed: 24.2ms preprocess, 5828.8ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1016.jpg: 960x960 1 face, 6550.6ms\n","Speed: 32.4ms preprocess, 6550.6ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1017.jpg: 960x960 1 face, 6278.4ms\n","Speed: 27.7ms preprocess, 6278.4ms inference, 5.1ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1018.jpg: 960x960 1 face, 5730.9ms\n","Speed: 28.0ms preprocess, 5730.9ms inference, 4.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1019.jpg: 960x960 1 face, 5865.4ms\n","Speed: 29.8ms preprocess, 5865.4ms inference, 3.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 102.jpg: 960x960 1 face, 5892.0ms\n","Speed: 20.8ms preprocess, 5892.0ms inference, 6.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1020.jpg: 960x960 1 face, 5932.6ms\n","Speed: 25.6ms preprocess, 5932.6ms inference, 4.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1021.jpg: 960x960 1 face, 6786.3ms\n","Speed: 26.8ms preprocess, 6786.3ms inference, 4.3ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1022.jpg: 960x960 1 face, 6551.2ms\n","Speed: 26.9ms preprocess, 6551.2ms inference, 6.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1023.jpg: 960x960 1 face, 5654.4ms\n","Speed: 27.9ms preprocess, 5654.4ms inference, 3.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1024.jpg: 960x960 1 face, 5759.3ms\n","Speed: 23.1ms preprocess, 5759.3ms inference, 5.1ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1025.jpg: 960x960 1 face, 5844.8ms\n","Speed: 26.1ms preprocess, 5844.8ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1026.jpg: 960x960 1 face, 5894.4ms\n","Speed: 24.0ms preprocess, 5894.4ms inference, 2.1ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1027.jpg: 960x960 1 face, 6456.1ms\n","Speed: 26.9ms preprocess, 6456.1ms inference, 2.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1028.jpg: 960x960 1 face, 6425.6ms\n","Speed: 34.8ms preprocess, 6425.6ms inference, 3.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1029.jpg: 960x960 1 face, 6084.1ms\n","Speed: 26.6ms preprocess, 6084.1ms inference, 5.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 103.jpg: 960x960 1 face, 5518.6ms\n","Speed: 66.4ms preprocess, 5518.6ms inference, 4.1ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1030.jpg: 960x960 1 face, 5923.4ms\n","Speed: 24.3ms preprocess, 5923.4ms inference, 4.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1031.jpg: 960x960 1 face, 5771.5ms\n","Speed: 37.2ms preprocess, 5771.5ms inference, 5.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1032.jpg: 960x960 2 faces, 6358.6ms\n","Speed: 24.1ms preprocess, 6358.6ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1033.jpg: 960x960 1 face, 5724.2ms\n","Speed: 31.2ms preprocess, 5724.2ms inference, 7.4ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1034.jpg: 960x960 1 face, 6957.3ms\n","Speed: 25.3ms preprocess, 6957.3ms inference, 8.9ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1035.jpg: 960x960 1 face, 7473.4ms\n","Speed: 37.7ms preprocess, 7473.4ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1036.jpg: 960x960 1 face, 5757.5ms\n","Speed: 26.5ms preprocess, 5757.5ms inference, 2.7ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1037.jpg: 960x960 1 face, 5899.7ms\n","Speed: 22.9ms preprocess, 5899.7ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1038.jpg: 960x960 1 face, 6338.6ms\n","Speed: 33.7ms preprocess, 6338.6ms inference, 2.2ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1039.jpg: 960x960 1 face, 5840.3ms\n","Speed: 27.1ms preprocess, 5840.3ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 104.jpg: 960x960 1 face, 5828.2ms\n","Speed: 21.6ms preprocess, 5828.2ms inference, 3.6ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1040.jpg: 960x960 1 face, 6012.2ms\n","Speed: 26.6ms preprocess, 6012.2ms inference, 4.6ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1041.jpg: 960x960 1 face, 5620.1ms\n","Speed: 24.6ms preprocess, 5620.1ms inference, 5.6ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1042.jpg: 960x960 2 faces, 7129.9ms\n","Speed: 24.5ms preprocess, 7129.9ms inference, 4.7ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1043.jpg: 960x960 1 face, 7066.0ms\n","Speed: 35.1ms preprocess, 7066.0ms inference, 4.9ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1044.jpg: 960x960 1 face, 7139.1ms\n","Speed: 33.5ms preprocess, 7139.1ms inference, 8.1ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1045.jpg: 960x960 1 face, 6816.2ms\n","Speed: 30.3ms preprocess, 6816.2ms inference, 4.1ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1046.jpg: 960x960 1 face, 6617.8ms\n","Speed: 31.1ms preprocess, 6617.8ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1047.jpg: 960x960 1 face, 6616.2ms\n","Speed: 29.4ms preprocess, 6616.2ms inference, 2.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1048.jpg: 960x960 1 face, 6784.8ms\n","Speed: 24.5ms preprocess, 6784.8ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1049.jpg: 960x960 1 face, 5971.6ms\n","Speed: 22.1ms preprocess, 5971.6ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 105.jpg: 960x960 1 face, 6553.7ms\n","Speed: 28.0ms preprocess, 6553.7ms inference, 4.3ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1050.jpg: 960x960 1 face, 5614.6ms\n","Speed: 25.7ms preprocess, 5614.6ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1051.jpg: 960x960 1 face, 5761.1ms\n","Speed: 25.7ms preprocess, 5761.1ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1052.jpg: 960x960 1 face, 5787.1ms\n","Speed: 23.7ms preprocess, 5787.1ms inference, 5.1ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1053.jpg: 960x960 1 face, 5913.7ms\n","Speed: 28.4ms preprocess, 5913.7ms inference, 4.1ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1054.jpg: 960x960 1 face, 5886.6ms\n","Speed: 29.6ms preprocess, 5886.6ms inference, 4.6ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1055.jpg: 960x960 1 face, 6140.5ms\n","Speed: 33.3ms preprocess, 6140.5ms inference, 4.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1056.jpg: 960x960 1 face, 6345.0ms\n","Speed: 25.5ms preprocess, 6345.0ms inference, 2.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1057.jpg: 960x960 1 face, 6851.9ms\n","Speed: 28.4ms preprocess, 6851.9ms inference, 4.1ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1058.jpg: 960x960 1 face, 7249.9ms\n","Speed: 34.5ms preprocess, 7249.9ms inference, 3.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1059.jpg: 960x960 1 face, 7281.2ms\n","Speed: 32.5ms preprocess, 7281.2ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 106.jpg: 960x960 1 face, 6716.8ms\n","Speed: 29.4ms preprocess, 6716.8ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1060.jpg: 960x960 1 face, 6638.3ms\n","Speed: 34.6ms preprocess, 6638.3ms inference, 7.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1061.jpg: 960x960 1 face, 6389.8ms\n","Speed: 28.7ms preprocess, 6389.8ms inference, 11.1ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1062.jpg: 960x960 1 face, 6221.1ms\n","Speed: 25.6ms preprocess, 6221.1ms inference, 3.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1063.jpg: 960x960 1 face, 5786.5ms\n","Speed: 37.0ms preprocess, 5786.5ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1064.jpg: 960x960 1 face, 5625.2ms\n","Speed: 25.5ms preprocess, 5625.2ms inference, 6.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1065.jpg: 960x960 1 face, 6696.2ms\n","Speed: 29.5ms preprocess, 6696.2ms inference, 3.5ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 1066.jpg: 960x960 1 face, 6589.0ms\n","Speed: 34.2ms preprocess, 6589.0ms inference, 4.1ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 107.jpg: 960x960 1 face, 6360.4ms\n","Speed: 30.6ms preprocess, 6360.4ms inference, 3.3ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 108.jpg: 960x960 1 face, 6171.3ms\n","Speed: 24.8ms preprocess, 6171.3ms inference, 3.4ms postprocess per image at shape (1, 3, 960, 960)\n","\n","image 1/1 c:\\Users\\dswal\\Desktop\\Progetto Computer Vision\\Progetto Computer Vision\\data\\images\\Copia di 109.jpg: 960x960 1 face, 6070.4ms\n","Speed: 23.7ms preprocess, 6070.4ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 960)\n","\n"]}],"source":["fd = FaceDetection(project_dir)\n","fd.face_detection()"]},{"cell_type":"markdown","metadata":{"id":"JSeNqWZgJmF0"},"source":["## Face Segmenetation"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":331,"status":"ok","timestamp":1718349734826,"user":{"displayName":"Giansimone Coccia","userId":"03098038543387348591"},"user_tz":-120},"id":"PCxqtvCkWTbl"},"outputs":[],"source":["class FaceSegmentation:\n","    def __init__(self, project_dir):\n","        # Imposta directory di progetto e dispositivo\n","        self._project_dir = project_dir\n","        self._device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","        # Inizializza i rilevatori e parser facciali\n","        self._face_detector = facer.face_detector('retinaface/mobilenet', device=self._device)\n","        self._face_parser = facer.face_parser('farl/lapa/448', device=self._device)\n","\n","    def process_images(self):\n","        all_segments = {}\n","        directory = os.path.join(self._project_dir, \"results/faces_facer\")\n","        self._clear_directory(directory)\n","        # Processa ciascuna immagine nella directory dei risultati\n","        for filename in os.listdir(os.path.join(self._project_dir, 'results/faces')):\n","            image_path = os.path.join(self._project_dir, 'results/faces', filename)\n","            try:\n","                image = self._load_image(image_path)\n","                faces = self._detect_faces(image)\n","                self._visualize_faces(image, faces)\n","                faces = self._parse_faces(image, faces)\n","                seg_probs = faces['seg']['logits'].softmax(dim=1)\n","                all_segments[filename] = self._segment_faces(image, seg_probs, faces)\n","                self._save_visualization(image, seg_probs, filename)\n","            except Exception as e:\n","                print(f\"Errore durante l'elaborazione di {filename}: {e}\")\n","                continue  # Passa alla prossima immagine\n","\n","        return all_segments\n","\n","    def _clear_directory(self, output_dir):\n","        # Verifica se la directory esiste\n","        if os.path.exists(output_dir):\n","            # Itera sui file nella directory e rimuovili\n","            for filename in os.listdir(output_dir):\n","                file_path = os.path.join(output_dir, filename)\n","                try:\n","                    if os.path.isfile(file_path) or os.path.islink(file_path):\n","                        os.unlink(file_path)\n","                    elif os.path.isdir(file_path):\n","                        shutil.rmtree(file_path)\n","                except Exception as e:\n","                    print(f\"Errore durante la rimozione di {file_path}: {e}\")\n","            print(f\"Contenuto di {output_dir} svuotato.\")\n","        else:\n","            print(f\"La directory {output_dir} non esiste.\")\n","\n","    def _load_image(self, image_path):\n","        # Carica e converte l'immagine nel formato richiesto\n","        image = facer.hwc2bchw(facer.read_hwc(image_path)).to(self._device)\n","        return image\n","\n","    def _detect_faces(self, image):\n","        # Rileva volti nell'immagine\n","        with torch.inference_mode():\n","            faces = self._face_detector(image)\n","        return faces\n","\n","    def _parse_faces(self, image, faces):\n","        # Analizza i volti rilevati\n","        with torch.inference_mode():\n","            faces = self._face_parser(image, faces)\n","        return faces\n","\n","    def _segment_faces(self, image, seg_probs, faces):\n","        # Segmenta i volti e i relativi componenti\n","        n_classes = seg_probs.size(1)\n","        segments = {}\n","        # Elenco delle classi da escludere\n","        exclude_classes = ['background', 'mouth']\n","\n","        for face_id in range(seg_probs.size(0)):\n","            for class_id in range(n_classes):\n","                # Ottieni il nome della classe corrente\n","                class_name = faces['seg']['label_names'][class_id]\n","                # Salta la classe se Ã¨ nell'elenco delle classi da escludere\n","                if class_name in exclude_classes:\n","                    continue\n","\n","                mask = (seg_probs[face_id, class_id] > 0.5).float()\n","                if mask.sum() > 0:\n","                    if face_id not in segments:\n","                        segments[face_id] = []\n","                    segments[face_id].append([mask, class_name])\n","\n","        return segments\n","\n","    def _save_visualization(self, image, seg_probs, filename):\n","        # Salva la visualizzazione delle segmentazioni\n","        vis_seg_probs = seg_probs.argmax(dim=1).float() / seg_probs.size(1) * 255\n","        vis_img = vis_seg_probs.sum(0, keepdim=True)\n","        vis_img_pil = to_pil_image(vis_img.byte())\n","        directory = os.path.join(self._project_dir, \"results/faces_facer\")\n","        if not os.path.exists(directory):\n","            os.makedirs(directory)\n","        vis_img_pil.save(os.path.join(directory, f'result_{filename.split(\"_\")[1]}_{filename.split(\"_\")[2]}.jpg'), format='JPEG')\n","\n","    def _visualize_faces(self, image, faces):\n","        # Mostra i volti rilevati\n","        facer.show_bchw(facer.draw_bchw(image, faces))\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9639,"status":"ok","timestamp":1718350586105,"user":{"displayName":"Giansimone Coccia","userId":"03098038543387348591"},"user_tz":-120},"id":"VnqyJgJ1T2oi","outputId":"4bf9c86d-b8fd-4a49-fca0-5752081b1560"},"outputs":[],"source":["# Inizializza e processa le immagini per la segmentazione facciale\n","face_segmentation = FaceSegmentation(project_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"0_qy02WAWJPu","outputId":"c109894f-d723-4212-fe70-e271c695d234"},"outputs":[],"source":["segments = face_segmentation.process_images()"]},{"cell_type":"markdown","metadata":{"id":"ddOErue6JyDs"},"source":["## Color Extraction"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":295,"status":"ok","timestamp":1718349738502,"user":{"displayName":"Giansimone Coccia","userId":"03098038543387348591"},"user_tz":-120},"id":"1_Fo2a-qtrjp"},"outputs":[],"source":["class ColorExtractor:\n","    def __init__(self, project_dir):\n","        # Imposta directory di progetto e dispositivo\n","        self._project_dir = project_dir\n","        self._device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","        print(f\"Utilizzando il dispositivo: {self._device}\")\n","\n","    def extract_dominant_colors(self, all_segments, normalize=True):\n","        start_time = time.time()\n","        dominant_colors = {}\n","\n","        with concurrent.futures.ThreadPoolExecutor() as executor:\n","            future_to_segment = {\n","                executor.submit(self._process_file_segments, filename, segments): (filename, segments)\n","                for filename, segments in all_segments.items()\n","            }\n","\n","            for future in concurrent.futures.as_completed(future_to_segment):\n","                filename, segments = future_to_segment[future]\n","                try:\n","                    file_dominant_colors = future.result()\n","                    dominant_colors.update(file_dominant_colors)\n","                except Exception as exc:\n","                    print(f'{filename} generated an exception: {exc}')\n","\n","                if time.time() - start_time > 1200:\n","                    break\n","\n","        if normalize:\n","            self._normalize_colors(dominant_colors)\n","\n","        return dominant_colors\n","\n","    def _process_file_segments(self, filename, segments):\n","        file_dominant_colors = {}\n","        image_tensor = self._load_image(os.path.join(self._project_dir, 'results/faces', filename))\n","        print(f\"Immagine {filename} caricata sul dispositivo: {image_tensor.device}\")\n","\n","        for face_id, segment_list in segments.items():\n","            for mask, label_name in segment_list:\n","                mask = mask.to(self._device)\n","                print(f\"Maschera per {label_name} sul dispositivo: {mask.device}\")\n","                colors = self._get_segmented_colors(image_tensor, mask)\n","                self._update_dominant_colors(file_dominant_colors, filename, face_id, label_name, colors)\n","        return file_dominant_colors\n","\n","    def _load_image(self, image_path):\n","        # Carica e converte l'immagine nel formato richiesto\n","        image = facer.hwc2bchw(facer.read_hwc(image_path)).to(self._device)\n","        return image\n","\n","    def _get_segmented_colors(self, image_tensor, mask):\n","        # Estrae i colori dai segmenti\n","        pixel_coords = torch.nonzero(mask)\n","        segmented_colors = [image_tensor[0, :, coord[0], coord[1]].cpu().numpy() for coord in pixel_coords]\n","        return np.array(segmented_colors) if segmented_colors else np.array([])\n","\n","    def _update_dominant_colors(self, dominant_colors, filename, face_id, label_name, segmented_colors):\n","        # Elenco delle classi da escludere\n","        exclude_classes = ['background', 'imouth']\n","        # Salta la classe se Ã¨ nell'elenco delle classi da escludere\n","        if label_name in exclude_classes:\n","            return dominant_colors\n","\n","        if segmented_colors.size > 0:\n","            # Applica MiniBatchKMeans\n","            minibatch_kmeans = MiniBatchKMeans(n_clusters=3, batch_size=100).fit(segmented_colors)\n","            # Ottieni i centroidi\n","            centroids = minibatch_kmeans.cluster_centers_\n","\n","            # Trova il colore piÃ¹ vicino a ciascun centroide\n","            closest_colors = []\n","            for centroid in centroids:\n","                distances = np.linalg.norm(segmented_colors - centroid, axis=1)\n","                closest_color = segmented_colors[np.argmin(distances)]\n","                closest_colors.append(closest_color)\n","\n","            if filename not in dominant_colors:\n","                dominant_colors[filename] = {}\n","            dominant_colors[filename][label_name] = np.array(closest_colors)\n","\n","        return dominant_colors\n","\n","    def save_dominant_colors_to_csv(self, dominant_colors, csv_filename='dominant_colors.csv'):\n","        # Verifica se la directory per il CSV esiste, altrimenti creala\n","        csv_dir = os.path.join(self._project_dir, 'results/csv')\n","        if not os.path.exists(csv_dir):\n","            os.makedirs(csv_dir)\n","\n","        csv_path = os.path.join(csv_dir, csv_filename)\n","\n","        # Lista delle etichette (deve corrispondere alle etichette nei dati)\n","        labels = [\n","            'face', 'rb', 'lb', 're', 'le', 'nose', 'ulip', 'llip', 'hair'  # Rimosso 'background' e 'imouth'\n","        ]\n","\n","        # Prepara l'intestazione del CSV\n","        columns = ['Filename']\n","        for label in labels:\n","            columns.extend([f'Color1-{label}', f'Color2-{label}', f'Color3-{label}'])\n","\n","        # Salva i colori dominanti in un file CSV\n","        with open(csv_path, mode='w', newline='') as csv_file:\n","            writer = csv.writer(csv_file)\n","            writer.writerow(columns)\n","\n","            for filename, labels_data in dominant_colors.items():\n","                row = [filename]\n","                for label in labels:\n","                    colors = labels_data.get(label, [np.nan, np.nan, np.nan])\n","                    row.extend(colors)\n","                writer.writerow(row)\n","\n","    def _are_colors_normalized(self, dominant_colors):\n","        # Controlla che tutti i valori siano normalizzati\n","        return all(\n","            (0 <= colors).all() and (colors <= 1).all()\n","            for faces in dominant_colors.values()\n","            for colors in faces.values()\n","        )\n","\n","    def _normalize_colors(self, dominant_colors):\n","        # Normalizza i valori RGB nel range [0, 1]\n","        for filename, faces in dominant_colors.items():\n","            for label_name, colors in faces.items():\n","                dominant_colors[filename][label_name] = colors / 255.0\n","\n","    def show_colors(self, dominant_colors):\n","        # Creare una copia di dominant_colors per evitare modifiche all'originale\n","        dominant_colors_copy = copy.deepcopy(dominant_colors)\n","\n","        # Normalizza i valori RGB nel range [0, 1] se non sono stati giÃ  normalizzati\n","        if not self._are_colors_normalized(dominant_colors_copy):\n","            self._normalize_colors(dominant_colors_copy)\n","\n","        # Visualizza i colori normalizzati\n","        for filename, faces in dominant_colors_copy.items():\n","            for label_name, colors in faces.items():\n","                print(f\"\\nFilename: {filename}, Label: {label_name}\")\n","                fig, ax = plt.subplots()\n","                ax.imshow([colors], aspect='auto')\n","                ax.axis('off')\n","                plt.show()\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["False\n"]}],"source":["print(torch.cuda.is_available())"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"kIy31n1WuDVU"},"outputs":[{"name":"stdout","output_type":"stream","text":["Utilizzando il dispositivo: cpu\n"]}],"source":["# Inizializza e estrai i colori dominanti dai segmenti facciali\n","color_extractor = ColorExtractor(project_dir)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"jHilpC7fWJPv","outputId":"3eb796e0-823c-49a0-a988-1e077803c4ef"},"outputs":[{"ename":"NameError","evalue":"name 'color_extractor' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dominant_colors \u001b[38;5;241m=\u001b[39m \u001b[43mcolor_extractor\u001b[49m\u001b[38;5;241m.\u001b[39mextract_dominant_colors(segments)\n","\u001b[1;31mNameError\u001b[0m: name 'color_extractor' is not defined"]}],"source":["dominant_colors = color_extractor.extract_dominant_colors(segments)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"elapsed":535,"status":"error","timestamp":1718301954225,"user":{"displayName":"Giansimone Coccia","userId":"03098038543387348591"},"user_tz":-120},"id":"mTc7n4MeMTG0","outputId":"ef5d1294-87cd-4665-a52b-2a9d7a486a11"},"outputs":[{"ename":"NameError","evalue":"name 'dominant_colors' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-ad461f63d446>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolor_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdominant_colors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'dominant_colors' is not defined"]}],"source":["color_extractor.show_colors(dominant_colors)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"executionInfo":{"elapsed":550,"status":"error","timestamp":1718301957563,"user":{"displayName":"Giansimone Coccia","userId":"03098038543387348591"},"user_tz":-120},"id":"rfZArW4ldrfJ","outputId":"d540fa0d-72bb-4080-e0fb-5cc6c5517986"},"outputs":[{"ename":"NameError","evalue":"name 'dominant_colors' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-ba05f7fa8127>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Utilizzo della funzione per salvare i dati in un file CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcolor_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dominant_colors_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdominant_colors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'dominant_colors' is not defined"]}],"source":["# Utilizzo della funzione per salvare i dati in un file CSV\n","color_extractor.save_dominant_colors_to_csv(dominant_colors)"]},{"cell_type":"markdown","metadata":{"id":"ycxHqLKojB_P"},"source":["## ColorClusterer"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":431,"status":"ok","timestamp":1718349742725,"user":{"displayName":"Giansimone Coccia","userId":"03098038543387348591"},"user_tz":-120},"id":"jIuWs52Qih5w"},"outputs":[],"source":["class ColorClusterer:\n","    def __init__(self, project_dir):\n","        self._project_dir = project_dir\n","        self._device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    def _extract_colors(self, colors):\n","        colori = []\n","        for image_name, volti in colors.items():\n","            colori.append([])\n","            for parte, colori_parte in volti.items():\n","                colori[-1].append(colori_parte)\n","        return np.array(colori)\n","\n","    def _visualize_clusters_3d(self, df, labels):\n","        tsne = TSNE(n_components=3, random_state=42)\n","        tsne_results = tsne.fit_transform(df.drop('cluster', axis=1))\n","\n","        fig = plt.figure(figsize=(12, 10))\n","        ax = fig.add_subplot(111, projection='3d')\n","\n","        for cluster in range(12):\n","            indices = np.where(labels == cluster)[0]\n","            ax.scatter(tsne_results[indices, 0], tsne_results[indices, 1], tsne_results[indices, 2],\n","                       label=f'Cluster {cluster}')\n","\n","        ax.set_title('t-SNE Visualization of Clusters (3D)')\n","        ax.legend()\n","        plt.show()\n","\n","    def _visualize_clusters_2d(self, df, labels):\n","        # Visualizzazione utilizzando t-SNE\n","        tsne = TSNE(n_components=2, random_state=42)\n","        tsne_results = tsne.fit_transform(df.drop('cluster', axis=1))\n","\n","        # Plot\n","        plt.figure(figsize=(10, 8))\n","        for cluster in range(12):\n","            indices = np.where(labels == cluster)[0]\n","            plt.scatter(tsne_results[indices, 0], tsne_results[indices, 1], label=f'Cluster {cluster}')\n","        plt.title('t-SNE Visualization of Clusters')\n","        plt.legend()\n","        plt.show()\n","\n","    def cluster(self, colors, image_paths=None):\n","        colori = self._extract_colors(colors)\n","        flattened_faces = colori.reshape(colori.shape[0], -1)\n","        df = pd.DataFrame(flattened_faces)\n","\n","        kmeans = KMeans(n_clusters=12, random_state=42)\n","        labels = kmeans.fit_predict(df)  # Perform KMeans clustering\n","\n","        df['cluster'] = labels  # Add the 'cluster' column with cluster labels\n","\n","        print(\"Cluster labels for each face:\")\n","        print(labels)\n","\n","        self._visualize_clusters_3d(df, labels)\n","        self._visualize_clusters_2d(df, labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dXR46p12m7VO"},"outputs":[],"source":["# Inizializza e estrai i colori dominanti dai segmenti facciali\n","color_clusterer = ColorClusterer(project_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":331,"status":"error","timestamp":1718295993410,"user":{"displayName":"Walter Di Sabatino","userId":"03659477704223957380"},"user_tz":-120},"id":"lc6xXS5WseCb","outputId":"8c2312dd-2701-4cb4-d7ca-2db4418d4b17"},"outputs":[{"ename":"ValueError","evalue":"n_samples=9 should be >= n_clusters=12.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-657c326b3db2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolor_clusterer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdominant_colors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-ad181e5ba860>\u001b[0m in \u001b[0;36mcluster\u001b[0;34m(self, colors, image_paths)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Perform KMeans clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m  \u001b[0;31m# Add the 'cluster' column with cluster labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1031\u001b[0m             \u001b[0mIndex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m \u001b[0mbelongs\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \"\"\"\n\u001b[0;32m-> 1033\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         )\n\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params_vs_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_params_vs_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params_vs_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_n_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_algorithm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_check_params_vs_input\u001b[0;34m(self, X, default_n_init)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;31m# n_clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;34mf\"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: n_samples=9 should be >= n_clusters=12."]}],"source":["color_clusterer.cluster(dominant_colors)"]},{"cell_type":"markdown","metadata":{"id":"mc3PQ6cWJxDB"},"source":["### Parte sotto da non considerare"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":357,"status":"error","timestamp":1716974016372,"user":{"displayName":"Walter Di Sabatino","userId":"03659477704223957380"},"user_tz":-120},"id":"zR9ZbuQCH7FX","outputId":"bfd53df4-4d05-499d-ee8d-a9464f0d67d7"},"outputs":[{"ename":"AssertionError","evalue":"Il percorso del modello non Ã¨ valido","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-89dbd4f06137>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assicurati che il percorso del modello sia corretto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Il percorso del modello non Ã¨ valido\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Run inference on an image with YOLOv8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Il percorso del modello non Ã¨ valido"]}],"source":["# Percorso del modello\n","model_path = os.path.join(project_dir, 'yolov8l-face.pt')\n","\n","# Assicurati che il percorso del modello sia corretto\n","assert os.path.exists(model_path), f\"Il percorso del modello non Ã¨ valido\"\n","# Run inference on an image with YOLOv8\n","model = YOLO(model_path)\n","results = model(os.path.join(project_dir, 'Faces.jpg'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"upZdwbnQ4Vwr"},"outputs":[],"source":["for i, result in enumerate(results):\n","    boxes = result.boxes.data  # Boxes object for bounding box outputs\n","\n","    result.save(filename='result.jpg')\n","    img = mpimg.imread('result.jpg')\n","    plt.imshow(img)\n","    # Itera attraverso tutte le bounding box individuate\n","    for j, box in enumerate(boxes):\n","        # Ottieni le coordinate della bounding box\n","        x_min, y_min, x_max, y_max, conf, cls = box.tolist()[:6]\n","\n","        # Ritaglia l'area corrispondente dall'immagine originale\n","        img = Image.open(os.path.join(project_dir, 'Faces.jpg'))\n","        cropped_img = img.crop((x_min, y_min, x_max, y_max))\n","\n","        # Salva l'immagine ritagliata\n","        directory = \"faces\"\n","        # Controllo se la cartella esiste, altrimenti la creo\n","        if not os.path.exists(directory):\n","            os.makedirs(directory)\n","        #shutil.rmtree(directory)\n","        cropped_img.save(os.path.join(directory,f'result_{i}_{\"0\" * (len(str(len(boxes))) - len(str(j)))}{j}.jpg'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_XV_IoSH-DGA"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["g-17S5ynJuDy","mc3PQ6cWJxDB"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
